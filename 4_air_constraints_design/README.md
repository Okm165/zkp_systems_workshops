# **Chapter 4: Algebraic Intermediate Representation (AIR) and Constraint Design**

**Abstract:** This chapter delves into the design of Algebraic Intermediate Representations (AIR), the formal language used to express computational integrity claims in systems like STARKs. Using the Fibonacci sequence as a guiding example, we walk through the process of arithmetization, converting a discrete execution trace into a set of algebraic constraints over a finite field. We meticulously construct boundary and transition constraints, unifying them into a single composition polynomial. The lecture then addresses the critical challenge of linking the prover's claims, explaining the necessity of an out-of-domain check to prevent spoofing and introducing the DEEP composition polynomial as an elegant mechanism for batch-verifying multiple evaluation claims. Finally, we analyze the final spot-check that anchors the entire proof to the initial commitments, providing a holistic and secure protocol.

**Learning Objectives:** Upon completion of this chapter, you will be able to:

- Explain the role of an execution trace and an AIR in converting a computational claim into a verifiable algebraic statement.
- Design and formulate boundary and transition constraints for a given state transition function using polynomials.
- Construct a composition polynomial to probabilistically unify multiple constraints into a single low-degree assertion.
- Articulate why an out-of-domain check is essential for soundness and how the DEEP composition polynomial is used to batch-verify evaluation proofs.
- Describe the final verification step that connects the DEEP proof back to the original trace and composition polynomial commitments.

---

### **Part 1: From Computation to Verifiable Claims**

In the domain of cryptographic proof systems, our primary objective is to verify the integrity of a computation without re-executing it. Systems like STARKs provide a framework to achieve this. The process begins with translating a computational task into a format amenable to mathematical proof—an **execution trace**.

An execution trace is a structured table where each row represents the state of a machine at a discrete time step. The prover, who performed the computation, asserts a **computational claim**: that their execution trace is valid. For this claim to be verifiable, the rules governing the computation's evolution must be expressed as a set of mathematical constraints. This formalization of constraints is known as an **Algebraic Intermediate Representation (AIR)**.

#### **The Computational Claim: A Fibonacci Sequence**

Let's consider the task of generating the `N`-th term of a Fibonacci-like sequence over a finite field `F`. The sequence `(a_i)` for `i >= 0` is defined by:

- `a_0 = 1`
- `a_1 = 1`
- `a_{n+2} = a_{n+1} + a_n` for all `n >= 0`

The prover's claim is that they have correctly computed the first `2^n` elements. Their evidence is an execution trace, a single-column table of `2^n` rows:

| Step (`i`) | Trace Column (`a_i`) |
| :--------: | :------------------: |
|     0      |        `a_0`         |
|     1      |        `a_1`         |
|     2      |        `a_2`         |
|    ...     |         ...          |
|  `2^n-1`   |     `a_{2^n-1}`      |

The verifier must confirm this trace adheres to the Fibonacci rules without inspecting every row.

---

### **Part 2: Arithmetization and Constraint Design**

The core of a STARK system is **arithmetization**, where we transform the discrete trace into a continuous algebraic object—a polynomial.

#### **The Trace Polynomial**

We select a multiplicative subgroup `D_S` of `F` with order `2^n`, generated by a primitive `2^n`-th root of unity, `g`. Thus, `D_S = {g^0, g^1, ..., g^{2^n-1}}`.

We define the **trace polynomial**, `t(x)`, as the unique polynomial of degree less than `2^n` that interpolates the trace values over `D_S`:
`t(g^i) = a_i` for `i` in `{0, 1, ..., 2^n-1}`

The computational claim now becomes a set of algebraic properties that `t(x)` must satisfy.

#### **Boundary Constraint Design**

Boundary constraints enforce specific states at known points. For our sequence, `a_0 = 1` and `a_1 = 1`, which translates to:
`t(g^0) = 1` and `t(g^1) = 1`

We enforce this by constructing a **boundary constraint polynomial**, `B(x)`. The principle is that if the constraints hold, `B(x)` must be a true polynomial, not a rational function.
`B(x) = (t(x) - P_B(x)) / ((x-g^0)(x-g^1))`

Here, `P_B(x)` is a polynomial that interpolates the boundary values (1 and 1) at the boundary points (`g^0` and `g^1`). The denominator, the **zerofier**, is a polynomial that is zero at exactly these points. This construction ensures that if `t(x)` matches `P_B(x)` at the boundaries, the division is exact and `B(x)` is a valid polynomial.

#### **Transition Constraint Design**

Transition constraints define the state evolution rule: `a_{i+2} = a_{i+1} + a_i`. This must hold for all valid steps, i.e., `i` in `{0, ..., 2^n-3}`. In polynomial terms, this becomes:
`t(x*g^2) - t(x*g) - t(x) = 0` for all `x` in `{g^0, ..., g^{2^n-3}}`

The **transition constraint polynomial**, `C(x)`, is formed similarly:
`C(x) = (t(x*g^2) - t(x*g) - t(x)) / Z_T(x)`

Where the zerofier `Z_T(x) = product_{i=0}^{2^n-3} (x-g^i)` enforces the rule across the valid portion of the trace.

---

### **Part 3: The Composition Polynomial and the Out-of-Domain Check**

To avoid multiple proofs, we combine all constraints into a single **composition polynomial**, `H(x)`, using random challenges `β_1, β_2` from the verifier:
`H(x) = β_1 * B(x) + β_2 * C(x)`

The prover's claim is now reduced to a single, powerful assertion: **`H(x)` is a low-degree polynomial.** The prover will use the FRI protocol to prove this.

#### **The First Challenge: Proving the Honesty of `H(x)`**

A crucial step is to ensure that the polynomial `H(x)` the prover commits to is the one correctly constructed from the trace polynomial `t(x)`. A verifier needs to check the formula for `H(x)` at some point. But which point?

> #### Deep Dive: The Flaw of In-Domain Checks
>
> If the verifier chose an in-domain point where a constraint applies (e.g., `x_0 = g^i` for `i < 2^n-2`), they would encounter an indeterminate form `0/0`.
>
> Consider the transition constraint `C(x_0)`. If the prover is honest, the numerator `t(x_0*g^2) - t(x_0*g) - t(x_0)` will be 0. However, the denominator `Z_T(x_0)` is _also_ 0 by definition of the zerofier.
>
> A cheating prover could commit to completely unrelated polynomials for `t(x)` and `H(x)`, and this check would still pass trivially. It reveals nothing about the relationship between the committed polynomials and is easily spoofed.

The solution is the **out-of-domain check**. The verifier chooses a random point `z` from `F` that is _not_ in the trace domain `D_S`. This ensures that the zerofier denominators in `B(z)` and `C(z)` are non-zero. The verifier then challenges the prover to provide the evaluations needed to compute `H(z)`:

- `H(z)`
- `t(z)`
- `t(z*g)`
- `t(z*g^2)`

The verifier uses the provided trace evaluations to locally compute what `H(z)` _should_ be and compares it to the value supplied by the prover. By the Schwartz-Zippel Lemma, if this check passes for a random `z`, it is highly probable that the prover's committed `H(x)` and `t(x)` are related by the correct formula _as polynomials_, not just at a few specific points.

This, however, introduces a new set of claims. The verifier has received these evaluations, but has no guarantee they are authentic. The prover must now prove that the values they sent are genuine evaluations of the polynomials they initially committed to.

---

### **Part 4: The DEEP Composition Polynomial and Final Verification**

The prover must now substantiate multiple claims simultaneously:

1.  **The Main Claim:** `H(x)` is a low-degree polynomial.
2.  **The Opening Claims:** The provided evaluations `H(z), t(z), t(z*g), t(z*g^2)` are correct.

Proving that an evaluation `P(z) = y` is correct for a committed polynomial `P(x)` is equivalent to proving that the quotient `(P(x) - y) / (x - z)` is a low-degree polynomial. Performing a separate FRI proof for each of these claims would be highly inefficient.

The **DEEP Composition Polynomial** provides an elegant solution by batching all these polynomiality proofs into one. The verifier supplies a new set of random challenges `γ_i` from `F`, and the prover constructs:
`Deep(x) = γ_1 * (H(x) - H(z))/(x - z) + γ_2 * (t(x) - t(z))/(x - z) + γ_3 * (t(x) - t(z*g))/(x - z*g) + γ_4 * (t(x) - t(z*g^2))/(x - z*g^2)`

The prover then executes a single FRI protocol to prove that `Deep(x)` is a low-degree polynomial.

> #### Deep Dive: The Final Link - The `Deep(x₀)` Check
>
> The FRI proof establishes that the prover knows _some_ low-degree polynomial, let's call it `D_committed(x)`. The final, critical link is to ensure that this is the _correct_ `Deep(x)` constructed from the _original_ committed polynomials, `[t]` and `[H]`. This is achieved by performing a spot-check at a random **in-domain** point `x₀`, which is one of the query points from the FRI protocol.
>
> 1.  **Prover's Role:** For the query point `x₀`, the prover provides:
>
>     - The evaluation `Deep(x_0)` along with its FRI proof.
>     - The evaluations `H(x_0)` and `t(x_0)` along with their **Merkle proofs** tying them back to the original commitments `[H]` and `[t]`.
>
> 2.  **Verifier's Role:** The verifier executes a crucial three-step verification:
>     - **Anchor the Ingredients:** The verifier first validates the Merkle proofs for `H(x_0)` and `t(x_0)`. This step makes these values cryptographically trustworthy anchors to the initial state of the protocol.
>     - **Reconstruct Locally:** Using these trusted values `H(x_0), t(x_0)`, along with the out-of-domain evaluations at `z` and the random challenges `γ_i`, the verifier calculates the value that `Deep(x_0)` _should_ have according to its public formula.
>     - **Compare and Conclude:** The verifier compares this locally computed value with the value of `Deep(x_0)` opened from the FRI proof. If they match, the loop is closed.
>
> This single check at `x₀` proves that the polynomial demonstrated to be low-degree by FRI is the same one that correctly binds the out-of-domain evaluations to the initially committed trace.

### **Conclusion**

The STARK protocol is a sequence of elegant reductions. A complex computational trace is reduced to a set of polynomial constraints. These are combined into a single composition polynomial, `H(x)`. The claim that `H(x)` is low-degree and correctly constructed is then further reduced into a series of opening claims. Finally, the **DEEP Composition Polynomial** batches these opening claims into a single object, whose integrity is proven with one FRI protocol. The check at an in-domain point `x₀` serves as the final anchor, binding the entire intricate web of claims back to the original commitments, thus providing a holistic and secure proof of computational integrity.

---

**Author:** [Okm165](https://github.com/Okm165) | [@bartolomeo_diaz](https://x.com/bartolomeo_diaz)
